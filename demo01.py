# -*- coding: utf-8 -*-
"""demo01.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ATD0aV6sk6Mi2Bd-RIvmS6tVfT7q9EF1
"""

# ============================================================
# 0. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (Colab ì „ìš©)
# ============================================================
!pip install mediapipe opencv-python matplotlib numpy pandas -q

# ============================================================
# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
# ============================================================
import cv2
import mediapipe as mp
import numpy as np
import matplotlib.pyplot as plt

from mpl_toolkits.mplot3d import Axes3D  # 3D í™œì„±í™”ìš© (ì‚¬ìš© ì•ˆ í•´ë„ í•„ìš”)
from google.colab import files

mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles

# ============================================================
# 2. ì´ë¯¸ì§€ ì—…ë¡œë“œ (CCTVì²˜ëŸ¼ ë³´ì´ëŠ” ì •ì  ì´ë¯¸ì§€)
# ============================================================
print("CCTV ìŠ¤íƒ€ì¼ ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ì˜ˆ: hallway.jpg)")
uploaded = files.upload()

# ì—…ë¡œë“œëœ ì²« ë²ˆì§¸ íŒŒì¼ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
image_path = list(uploaded.keys())[0]
print("ì‚¬ìš©í•  ì´ë¯¸ì§€:", image_path)

# ============================================================
# 3. Pose Detection í•¨ìˆ˜ ì •ì˜ (ì´ë¯¸ì§€ -> MediaPipe Pose)
#     ì´ ë¶€ë¶„ì´ Transfer Learning ëª¨ë¸ í™œìš© ì§€ì 
# ============================================================
def run_mediapipe_pose(image_path):
    # OpenCVë¡œ ì´ë¯¸ì§€ ë¡œë“œ (BGR)
    image_bgr = cv2.imread(image_path)
    if image_bgr is None:
        raise FileNotFoundError(f"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")

    # ì‹œê°í™”ë¥¼ ìœ„í•´ ì›ë³¸ ë³µì‚¬
    image_bgr_copy = image_bgr.copy()

    # BGR -> RGB (MediaPipeëŠ” RGB ì‚¬ìš©)
    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)

    #  Transfer Learning: ì‚¬ì „í•™ìŠµëœ Pose ëª¨ë¸ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    with mp_pose.Pose(
        static_image_mode=True,        # ì •ì  ì´ë¯¸ì§€ì´ë¯€ë¡œ True
        model_complexity=1,           # 0,1,2 ì¤‘ 1 ì •ë„ë©´ ì¶©ë¶„
        enable_segmentation=False,
        min_detection_confidence=0.5  # ë””í…ì…˜ ì‹ ë¢°ë„
    ) as pose:
        results = pose.process(image_rgb)

        # pose_landmarks (2D)ì™€ pose_world_landmarks (3D) ëª¨ë‘ í¬í•¨
        return image_bgr_copy, results

# ============================================================
# 4. 2D Pose ì˜¤ë²„ë ˆì´ (ì…ë ¥ ì´ë¯¸ì§€ ìœ„ì— ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸°)
# ============================================================
def draw_2d_pose_overlay(image_bgr, results):
    if not results.pose_landmarks:
        print("[WARN] í¬ì¦ˆê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return image_bgr

    overlay = image_bgr.copy()

    # MediaPipe ê¸°ë³¸ ìŠ¤íƒ€ì¼ë¡œ ëœë“œë§ˆí¬ + ì—°ê²°ì„  ê·¸ë¦¬ê¸°
    mp_drawing.draw_landmarks(
        overlay,
        results.pose_landmarks,
        mp_pose.POSE_CONNECTIONS,
        landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()
    )
    return overlay

def show_bgr_image_in_colab(image_bgr, title="Image"):
    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
    plt.figure(figsize=(6, 6))
    plt.imshow(image_rgb)
    plt.title(title)
    plt.axis('off')
    plt.show()

# ============================================================
# 5. 3D ìŠ¤ì¼ˆë ˆí†¤ì„ ê·¸ë¦¬ê¸° ìœ„í•œ ìœ í‹¸ í•¨ìˆ˜ë“¤
#    (MediaPipe world_landmarks â†’ numpy ë°°ì—´ â†’ 3D plot)
# ============================================================
def extract_world_landmarks(results):
    """
    MediaPipe Pose ê²°ê³¼ì—ì„œ 3D world_landmarksë¥¼ ì¶”ì¶œí•˜ì—¬
    (N, 3) numpy ë°°ì—´ê³¼ visibility ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
    """
    if not results.pose_world_landmarks:
        print("[WARN] 3D world_landmarksê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, None

    landmarks = results.pose_world_landmarks.landmark
    xs, ys, zs, vs = [], [], [], []
    for lm in landmarks:
        xs.append(lm.x)
        ys.append(lm.y)
        zs.append(lm.z)
        vs.append(lm.visibility)

    points_3d = np.array([xs, ys, zs]).T  # (33, 3)
    visibility = np.array(vs)            # (33,)
    return points_3d, visibility


def get_pose_connections():
    """
    MediaPipe Pose 33ê°œ ëœë“œë§ˆí¬ë¥¼ ì—°ê²°í•˜ëŠ” ìŠ¤ì¼ˆë ˆí†¤ ì •ì˜.
    (ê³µì‹ connectionsë¥¼ ì¨ë„ ë˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” í•µì‹¬ ë¼ˆëŒ€ë§Œ ê°„ë‹¨ ì •ì˜)
    ì¸ë±ìŠ¤ëŠ” MediaPipe Pose ê¸°ì¤€:
      11: ì™¼ ì–´ê¹¨, 12: ì˜¤ë¥¸ ì–´ê¹¨, 13/14: íŒ”ê¿ˆì¹˜, 15/16: ì†ëª©,
      23/24: ê³¨ë°˜, 25/26: ë¬´ë¦, 27/28: ë°œëª©, 29/30, 31/32: ë°œ
    """
    connections = [
        # ìƒì²´
        (11, 12),   # ì–´ê¹¨
        (11, 13), (13, 15),  # ì™¼íŒ”
        (12, 14), (14, 16),  # ì˜¤ë¥¸íŒ”
        (11, 23), (12, 24),  # ëª¸í†µ ì˜† ë¼ì¸
        (23, 24),            # ê³¨ë°˜

        # ì™¼ìª½ ë‹¤ë¦¬
        (23, 25), (25, 27), (27, 29), (29, 31),

        # ì˜¤ë¥¸ìª½ ë‹¤ë¦¬
        (24, 26), (26, 28), (28, 30), (30, 32),
    ]
    return connections


def plot_3d_skeleton(points_3d, visibility=None, vis_thresh=0.5):
    """
    MediaPipe world ì¢Œí‘œ (x, y, z)ë¥¼ ì‚¬ëŒì´ ì„œ ìˆëŠ” ëŠë‚Œìœ¼ë¡œ ë‹¤ì‹œ ë°°ì¹˜:
      - Xì¶• : ì¢Œ/ìš° (x ê·¸ëŒ€ë¡œ)
      - Yì¶• : ê¹Šì´  (ì¹´ë©”ë¼ì—ì„œ ë©€ì–´ì§€ëŠ” ë°©í–¥, z ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê±°ë‚˜ -zë¡œ ë°”ê¿”ë„ OK)
      - Zì¶• : ìœ„/ì•„ë˜ (-y ë¡œ ë’¤ì§‘ì–´ì„œ, ë¨¸ë¦¬ê°€ ìœ„ë¡œ ê°€ê²Œ)
    """
    if points_3d is None:
        print("[ERROR] 3D í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # --- ì¢Œí‘œ ë³€í™˜ ---
    xs = points_3d[:, 0]        # ì¢Œ/ìš°
    ys = points_3d[:, 2]        # ê¹Šì´ (ì›í•˜ë©´ -points_3d[:,2] ë¡œ ë°˜ëŒ€ë¡œ)
    zs = -points_3d[:, 1]       # ìœ„/ì•„ë˜ (yê°€ ì•„ë˜ë¡œ +ë‹ˆê¹Œ ë¶€í˜¸ ë°˜ì „)

    fig = plt.figure(figsize=(6, 6))
    ax = fig.add_subplot(111, projection='3d')

    # ì „ì²´ í¬ì¸íŠ¸ ì°ê¸°
    ax.scatter(xs, ys, zs, s=20, alpha=0.6)

    connections = get_pose_connections()

    for i, j in connections:
        if i >= len(points_3d) or j >= len(points_3d):
            continue

        if visibility is not None:
            if visibility[i] < vis_thresh or visibility[j] < vis_thresh:
                continue

        x_line = [points_3d[i, 0], points_3d[j, 0]]
        y_line = [points_3d[i, 2], points_3d[j, 2]]
        z_line = [-points_3d[i, 1], -points_3d[j, 1]]
        ax.plot(x_line, y_line, z_line)

    ax.set_xlabel("X (left-right)")
    ax.set_ylabel("Y (depth)")
    ax.set_zlabel("Z (up-down)")

    # ì¶• ë¹„ìœ¨ ë§ì¶”ê¸°
    max_range = np.array([
        xs.max() - xs.min(),
        ys.max() - ys.min(),
        zs.max() - zs.min()
    ]).max()

    mid_x = (xs.max() + xs.min()) * 0.5
    mid_y = (ys.max() + ys.min()) * 0.5
    mid_z = (zs.max() + zs.min()) * 0.5

    ax.set_xlim(mid_x - max_range / 2, mid_x + max_range / 2)
    ax.set_ylim(mid_y - max_range / 2, mid_y + max_range / 2)
    ax.set_zlim(mid_z - max_range / 2, mid_z + max_range / 2)

    # ì‚¬ëŒì„ ì•½ê°„ ëŒ€ê°ì„  ìœ„ì—ì„œ ë³´ëŠ” ëŠë‚Œ
    ax.view_init(elev=20, azim=-60)
    plt.tight_layout()
    plt.show()

# ============================================================
# 6. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰:
#    ì´ë¯¸ì§€ -> MediaPipe Pose -> 2D í¬ì¦ˆ ì˜¤ë²„ë ˆì´ -> 3D ìŠ¤ì¼ˆë ˆí†¤
# ============================================================
# 1) Pose ì¶”ë¡ 
image_bgr, results = run_mediapipe_pose(image_path)

# 2) 2D í¬ì¦ˆ ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ í‘œì‹œ
overlay_bgr = draw_2d_pose_overlay(image_bgr, results)
show_bgr_image_in_colab(image_bgr, title="Input Image")
show_bgr_image_in_colab(overlay_bgr, title="Pose Overlay (2D)")

# 3) 3D world_landmarks ì¶”ì¶œ
points_3d, visibility = extract_world_landmarks(results)

# 4) 3D ìŠ¤ì¼ˆë ˆí†¤ ì‹œê°í™”
plot_3d_skeleton(points_3d, visibility=visibility, vis_thresh=0.5)

import cv2
import numpy as np
import mediapipe as mp
import pandas as pd
import os
import argparse

mp_pose = mp.solutions.pose
pose = mp_pose.Pose(static_image_mode=True, model_complexity=1, enable_segmentation=False)
mp_drawing = mp.solutions.drawing_utils
mp_style = mp.solutions.drawing_styles

def imread_rgb(path):
    """ì´ë¯¸ì§€ë¥¼ RGBë¡œ ì½ê¸°"""
    bgr = cv2.imread(path)
    if bgr is None:
        raise FileNotFoundError(f"ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
    return cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)

def mediapipe_infer(rgb):
    """MediaPipe Pose ì¶”ë¡ """
    res = pose.process(rgb)
    return res.pose_landmarks if res.pose_landmarks else None

def to_dataframe(landmarks, w, h):
    """ì •ê·œí™” ì¢Œí‘œ(x,yâˆˆ[0,1], zëŠ” ìƒëŒ€ ê¹Šì´) DataFrameìœ¼ë¡œ ë³€í™˜"""
    data = []
    for i, lm in enumerate(landmarks.landmark):
        data.append({
            "id": i,
            "x": lm.x,
            "y": lm.y,
            "z": lm.z,
            "visibility": lm.visibility
        })
    df = pd.DataFrame(data)
    return df

def draw_pose(rgb, landmarks):
    """ì´ë¯¸ì§€ ìœ„ì— í¬ì¦ˆ ì˜¤ë²„ë ˆì´"""
    annotated = rgb.copy()
    mp_drawing.draw_landmarks(
        annotated,
        landmarks,
        mp_pose.POSE_CONNECTIONS,
        landmark_drawing_spec=mp_style.get_default_pose_landmarks_style())
    return annotated

def main(image_path, out_csv):
    os.makedirs(os.path.dirname(out_csv), exist_ok=True)

    rgb = imread_rgb(image_path)
    h, w = rgb.shape[:2]

    landmarks = mediapipe_infer(rgb)
    if landmarks is None:
        print("âŒ í¬ì¦ˆë¥¼ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì´ë¯¸ì§€ë¡œ ì‹œë„í•˜ì„¸ìš”.")
        return

    df = to_dataframe(landmarks, w, h)
    df.to_csv(out_csv, index=False)
    print(f"âœ… CSV ì €ì¥ ì™„ë£Œ: {out_csv}")
    print(df.head())

    # ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥ (ì„ íƒ)
    annotated = draw_pose(rgb, landmarks)
    preview_path = out_csv.replace("keypoints", "preview").replace(".csv", "_overlay.jpg")
    os.makedirs(os.path.dirname(preview_path), exist_ok=True)
    cv2.imwrite(preview_path, cv2.cvtColor(annotated, cv2.COLOR_RGB2BGR))
    print(f"ğŸ–¼ï¸ í¬ì¦ˆ ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥: {preview_path}")

if __name__ == "__main__":
    # In Colab, we don't use argparse to get command line arguments.
    # We will directly call the main function with the image path from the previous step.
    # The image path is stored in the variable 'image_path' from the file upload cell (hzPFI_sfCzuy).
    # We'll also set a default output path for the CSV.

    # Ensure image_path exists from the previous cell execution
    if 'image_path' not in globals():
        raise FileNotFoundError("Image file path not found. Please run the file upload cell above.")

    output_csv_path = "data/keypoints/pose_sample.csv"
    main(image_path, output_csv_path)

!ls -R data

import pandas as pd
df = pd.read_csv("data/keypoints/pose_sample.csv")
df.head()